import { expect } from 'chai';
import * as sinon from 'sinon';
import * as vscode from 'vscode';
import { InterventionEngine } from '../src/analyzers/InterventionEngine';
import { FileAnalysis, QualityIssueReport, QualityLevel } from '../src/types/common';
import { QualityAnalyzer } from '../src/analyzers/QualityAnalyzer';

// Mock VS Code APIs
const mockOutputChannel = {
  appendLine: sinon.stub(),
  show: sinon.stub(),
  dispose: sinon.stub(),
} as unknown as vscode.OutputChannel;

const mockTerminal = {
  sendText: sinon.stub(),
  show: sinon.stub(),
} as unknown as vscode.Terminal;

const mockWindow = {
  activeTerminal: mockTerminal,
  showWarningMessage: sinon.stub(),
  showErrorMessage: sinon.stub(),
  showInformationMessage: sinon.stub(),
  createWebviewPanel: sinon.stub().returns({
    webview: { html: '' },
    dispose: sinon.stub(),
  }),
} as unknown as typeof vscode.window;

// Mock QualityAnalyzer
class MockQualityAnalyzer extends QualityAnalyzer {
  generateQualityReport(analysis: FileAnalysis): QualityIssueReport {
    return {
      file: analysis.filePath,
      totalIssues: analysis.detectionResult.patterns.length,
      criticalCount: analysis.detectionResult.qualityLevel === 'CRITICAL' ? 1 : 0,
      highCount: analysis.detectionResult.qualityLevel === 'HIGH' ? 1 : 0,
      issues: [], // Simplified for test
      aiInstruction: `AI instruction for ${analysis.filePath} with level ${analysis.detectionResult.qualityLevel}`,
    };
  }
}

describe('InterventionEngine', () => {
  let interventionEngine: InterventionEngine;
  let sandbox: sinon.SinonSandbox;

  beforeEach(() => {
    sandbox = sinon.createSandbox();

    // Replace the real QualityAnalyzer with our mock
    sandbox.stub(InterventionEngine.prototype, 'qualityAnalyzer' as any).value(new MockQualityAnalyzer());

    // Mock vscode.window
    Object.defineProperty(vscode, 'window', {
      value: mockWindow,
      writable: true,
    });

    interventionEngine = new InterventionEngine(mockOutputChannel);
  });

  afterEach(() => {
    sandbox.restore();
  });

  it('should trigger AI intervention for CRITICAL quality level and no active intervention', () => {
    const analysis: FileAnalysis = {
      filePath: 'test.ts',
      timestamp: Date.now(),
      detectionResult: {
        qualityLevel: 'CRITICAL' as QualityLevel,
        score: 100,
        patterns: [{ category: 'SECURITY_ISSUES', match: 'eval(', pattern: 'eval', weight: 1, source: 'test' }],
      },
      triggerType: 'manual',
      interventionLevel: 'none'
    };
    expect(interventionEngine.shouldTriggerAIIntervention(analysis)).to.be.true;
  });

  it('should not trigger AI intervention for non-CRITICAL quality level', () => {
    const analysis: FileAnalysis = {
      filePath: 'test.ts',
      timestamp: Date.now(),
      detectionResult: {
        qualityLevel: 'HIGH' as QualityLevel,
        score: 50,
        patterns: [],
      },
      triggerType: 'manual',
      interventionLevel: 'none'
    };
    expect(interventionEngine.shouldTriggerAIIntervention(analysis)).to.be.false;
  });

  it('should not trigger AI intervention if an intervention is already active', async () => {
    const analysis: FileAnalysis = {
      filePath: 'test.ts',
      timestamp: Date.now(),
      detectionResult: {
        qualityLevel: 'CRITICAL' as QualityLevel,
        score: 100,
        patterns: [{ category: 'SECURITY_ISSUES', match: 'eval(', pattern: 'eval', weight: 1, source: 'test' }],
      },
      triggerType: 'manual',
      interventionLevel: 'none'
    };

    // Manually set intervention as active (simulating a previous intervention)
    await interventionEngine.performAutomaticAIIntervention(analysis);
    expect(interventionEngine.shouldTriggerAIIntervention(analysis)).to.be.false;
  });

  it('should not trigger AI intervention if within cooldown period', async () => {
    const analysis: FileAnalysis = {
      filePath: 'test.ts',
      timestamp: Date.now(),
      detectionResult: {
        qualityLevel: 'CRITICAL' as QualityLevel,
        score: 100,
        patterns: [{ category: 'SECURITY_ISSUES', match: 'eval(', pattern: 'eval', weight: 1, source: 'test' }],
      },
      triggerType: 'manual',
      interventionLevel: 'none'
    };

    const clock = sinon.useFakeTimers();
    await interventionEngine.performAutomaticAIIntervention(analysis);
    clock.tick(10000); // Advance time by 10 seconds (less than 30s cooldown)
    expect(interventionEngine.shouldTriggerAIIntervention(analysis)).to.be.false;
    clock.restore();
  });

  it('should send AI correction to terminal when performing automatic intervention', async () => {
    const analysis: FileAnalysis = {
      filePath: 'test.ts',
      timestamp: Date.now(),
      detectionResult: {
        qualityLevel: 'CRITICAL' as QualityLevel,
        score: 100,
        patterns: [{ category: 'SECURITY_ISSUES', match: 'eval(', pattern: 'eval', weight: 1, source: 'test' }],
      },
      triggerType: 'manual',
      interventionLevel: 'none'
    };
    const sendTextSpy = sandbox.spy(mockTerminal, 'sendText');

    await interventionEngine.performAutomaticAIIntervention(analysis);

    expect(sendTextSpy.calledWith(`# AI Quality Issue Report for test.ts`)).to.be.true;
    expect(sendTextSpy.calledWith(`echo "AI instruction for test.ts with level CRITICAL"`)).to.be.true;
  });

  it('should show critical issues block and request AI fix on user action', async () => {
    const report: QualityIssueReport = {
      file: 'critical.ts',
      totalIssues: 1,
      criticalCount: 1,
      highCount: 0,
      issues: [],
      aiInstruction: 'Fix this critical issue',
    };
    const showErrorMessageStub = sandbox.stub(mockWindow, 'showErrorMessage');

    // Simulate user clicking 'Request AI Fix'
    showErrorMessageStub.returns(Promise.resolve('Request AI Fix'));
    const sendTextSpy = sandbox.spy(mockTerminal, 'sendText');

    await interventionEngine.showCriticalIssuesBlock(report);

    expect(showErrorMessageStub.calledOnce).to.be.true;
    expect(sendTextSpy.calledWith(`echo "Fix this critical issue"`)).to.be.true;
  });

  it('should show detailed quality report on user action', async () => {
    const report: QualityIssueReport = {
      file: 'details.ts',
      totalIssues: 1,
      criticalCount: 0,
      highCount: 1,
      issues: [],
      aiInstruction: 'Show details',
    };
    const showWarningMessageStub = sandbox.stub(mockWindow, 'showWarningMessage');
    const createWebviewPanelStub = sandbox.stub(mockWindow, 'createWebviewPanel');

    // Simulate user clicking 'Show Details'
    showWarningMessageStub.returns(Promise.resolve('Show Details'));

    await interventionEngine.requestUserApprovedAIFix(report);

    expect(showWarningMessageStub.calledOnce).to.be.true;
    expect(createWebviewPanelStub.calledOnce).to.be.true;
  });
});

